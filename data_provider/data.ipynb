{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Custom_Stock(Dataset):\n",
    "    def __init__(self, args, root_path, flag='train', size=None,\n",
    "                 features='S', data_path='/home/liyuante/llm4ts/us_stock.csv',\n",
    "                 target='OT', scale=True, timeenc=0, freq='h', seasonal_patterns=None):\n",
    "        self.args = args\n",
    "        if size == None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "\n",
    "        cols = list(df_raw.columns)\n",
    "        cols.remove(self.target)\n",
    "        cols.remove('date')\n",
    "        cols.remove('PERMNO')\n",
    "        df_raw = df_raw[['PERMNO', 'date'] + cols + [self.target]]\n",
    "\n",
    "        # 分组处理每个股票的数据\n",
    "        grouped = df_raw.groupby('PERMNO')\n",
    "        data_list = []\n",
    "        stamp_list = []\n",
    "\n",
    "        for permno, group in grouped:\n",
    "            group = group.sort_values('date')\n",
    "            num_train = int(len(group) * 0.7)\n",
    "            num_test = int(len(group) * 0.2)\n",
    "            num_vali = len(group) - num_train - num_test\n",
    "            border1s = [0, num_train - self.seq_len, len(group) - num_test - self.seq_len]\n",
    "            border2s = [num_train, num_train + num_vali, len(group)]\n",
    "            border1 = border1s[self.set_type]\n",
    "            border2 = border2s[self.set_type]\n",
    "\n",
    "            if self.features == 'M' or self.features == 'MS':\n",
    "                cols_data = group.columns[2:]  # 去掉 PERMNO 和 date 列\n",
    "                df_data = group[cols_data]\n",
    "            elif self.features == 'S':\n",
    "                df_data = group[[self.target]]\n",
    "\n",
    "            if self.scale:\n",
    "                train_data = df_data[border1s[0]:border2s[0]]\n",
    "                self.scaler.fit(train_data.values)\n",
    "                data = self.scaler.transform(df_data.values)\n",
    "            else:\n",
    "                data = df_data.values\n",
    "\n",
    "            df_stamp = group[['date']][border1:border2]\n",
    "            df_stamp['date'] = pd.to_datetime(df_stamp.date)\n",
    "            if self.timeenc == 0:\n",
    "                df_stamp['month'] = df_stamp.date.apply(lambda row: row.month, 1)\n",
    "                df_stamp['day'] = df_stamp.date.apply(lambda row: row.day, 1)\n",
    "                df_stamp['weekday'] = df_stamp.date.apply(lambda row: row.weekday(), 1)\n",
    "                df_stamp['hour'] = df_stamp.date.apply(lambda row: row.hour, 1)\n",
    "                data_stamp = df_stamp.drop(['date'], 1).values\n",
    "            elif self.timeenc == 1:\n",
    "                data_stamp = time_features(pd.to_datetime(df_stamp['date'].values), freq=self.freq)\n",
    "                data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "            data_list.append(data[border1:border2])\n",
    "            stamp_list.append(data_stamp)\n",
    "\n",
    "        self.data_x = np.concatenate(data_list, axis=0)\n",
    "        self.data_y = self.data_x\n",
    "        self.data_stamp = np.concatenate(stamp_list, axis=0)\n",
    "\n",
    "        if self.set_type == 0 and self.args.augmentation_ratio > 0:\n",
    "            self.data_x, self.data_y, augmentation_tags = run_augmentation_single(self.data_x, self.data_y, self.args)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PERMNO       date  BIDLO  ASKHI    PRC      VOL        RET    BID    ASK  \\\n",
      "0   10107 1986-02-28    NaN    NaN    NaN      NaN        NaN    NaN    NaN   \n",
      "1   10107 1986-03-31  26.00  29.50  27.50  64786.0          C  27.25  27.50   \n",
      "2   10107 1986-04-30  27.25  34.00  32.25  19056.0   0.172727  31.75  32.25   \n",
      "3   10107 1986-05-30  31.00  34.75  34.75   9810.0   0.077519  34.75  35.00   \n",
      "4   10107 1986-06-30  29.75  34.25  30.75  10238.0  -0.115108  30.50  30.75   \n",
      "\n",
      "   ALTPRC  SPREAD    ALTPRCDT       RETX  \n",
      "0   28.00     NaN  1986-03-13        NaN  \n",
      "1   27.50     NaN  1986-03-31          C  \n",
      "2   32.25     NaN  1986-04-30   0.172727  \n",
      "3   34.75     NaN  1986-05-30   0.077519  \n",
      "4   30.75     NaN  1986-06-30  -0.115108  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_444156/3325455364.py:38: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  processed = grouped.apply(process_group)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/us_stock.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "target = 'RETX'\n",
    "cols = list(df.columns)\n",
    "cols.remove(target)\n",
    "cols.remove('date')\n",
    "cols.remove('PERMNO')\n",
    "cols.remove('SPREAD')\n",
    "cols.remove('RET')\n",
    "cols.remove('ALTPRCDT')\n",
    "cols.remove('BID')\n",
    "cols.remove('ASK')\n",
    "\n",
    "df = df[['PERMNO', 'date'] + cols + [target]]\n",
    "\n",
    "# 按照股票代码划分数据\n",
    "grouped = df.groupby('PERMNO')\n",
    "\n",
    "# 定义一个函数来处理每个股票组的数据\n",
    "def process_group(group):\n",
    "    # 将字符 'B', 'C' 转化为 NaN\n",
    "    group = group.replace({'B': np.nan, 'C': np.nan})\n",
    "    \n",
    "    # 将 BIDLO, ASKHI, PRC, VOL, ALTPRC 转化为比值\n",
    "    group[['BIDLO', 'ASKHI', 'PRC', 'VOL', 'ALTPRC']] = group[['BIDLO', 'ASKHI', 'PRC', 'VOL', 'ALTPRC']].apply(pd.to_numeric, errors='coerce')\n",
    "    group[['BIDLO', 'ASKHI', 'PRC', 'VOL', 'ALTPRC']] = group[['BIDLO', 'ASKHI', 'PRC', 'VOL', 'ALTPRC']].div(group[['BIDLO', 'ASKHI', 'PRC', 'VOL', 'ALTPRC']].shift(1))\n",
    "    \n",
    "    return group\n",
    "\n",
    "# 对每个组应用该函数\n",
    "processed = grouped.apply(process_group)\n",
    "\n",
    "# 重置索引\n",
    "processed.reset_index(drop=True, inplace=True)\n",
    "\n",
    "processed.dropna(inplace=True)\n",
    "\n",
    "processed.to_csv('/home/liyuante/llm4ts/us_stock_processed.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>ALTPRC</th>\n",
       "      <th>RETX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10107</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>1.048077</td>\n",
       "      <td>1.152542</td>\n",
       "      <td>1.172727</td>\n",
       "      <td>0.294138</td>\n",
       "      <td>1.172727</td>\n",
       "      <td>0.172727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10107</td>\n",
       "      <td>1986-05-30</td>\n",
       "      <td>1.137615</td>\n",
       "      <td>1.022059</td>\n",
       "      <td>1.077519</td>\n",
       "      <td>0.514798</td>\n",
       "      <td>1.077519</td>\n",
       "      <td>0.077519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10107</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>0.985612</td>\n",
       "      <td>0.884892</td>\n",
       "      <td>1.043629</td>\n",
       "      <td>0.884892</td>\n",
       "      <td>-0.115108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10107</td>\n",
       "      <td>1986-07-31</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>1.568373</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>-0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10107</td>\n",
       "      <td>1986-08-29</td>\n",
       "      <td>1.009174</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12337</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-08-31</td>\n",
       "      <td>1.064389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941169</td>\n",
       "      <td>0.585500</td>\n",
       "      <td>0.941169</td>\n",
       "      <td>-0.058831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12338</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>1.057934</td>\n",
       "      <td>1.143003</td>\n",
       "      <td>1.057934</td>\n",
       "      <td>0.057934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-10-31</td>\n",
       "      <td>1.069776</td>\n",
       "      <td>1.057067</td>\n",
       "      <td>1.062219</td>\n",
       "      <td>1.037789</td>\n",
       "      <td>1.062219</td>\n",
       "      <td>0.062219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12340</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>1.042063</td>\n",
       "      <td>1.025157</td>\n",
       "      <td>1.032508</td>\n",
       "      <td>0.896984</td>\n",
       "      <td>1.032508</td>\n",
       "      <td>0.032508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12341</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.971803</td>\n",
       "      <td>0.995099</td>\n",
       "      <td>0.952077</td>\n",
       "      <td>1.102215</td>\n",
       "      <td>0.952077</td>\n",
       "      <td>-0.047923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12342 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PERMNO        date     BIDLO     ASKHI       PRC       VOL    ALTPRC  \\\n",
       "0       10107  1986-04-30  1.048077  1.152542  1.172727  0.294138  1.172727   \n",
       "1       10107  1986-05-30  1.137615  1.022059  1.077519  0.514798  1.077519   \n",
       "2       10107  1986-06-30  0.959677  0.985612  0.884892  1.043629  0.884892   \n",
       "3       10107  1986-07-31  0.915966  0.912409  0.926829  1.568373  0.926829   \n",
       "4       10107  1986-08-29  1.009174  0.980000  1.000000  0.575388  1.000000   \n",
       "...       ...         ...       ...       ...       ...       ...       ...   \n",
       "12337   92655  2023-08-31  1.064389  1.000000  0.941169  0.585500  0.941169   \n",
       "12338   92655  2023-09-29  0.999287  0.998728  1.057934  1.143003  1.057934   \n",
       "12339   92655  2023-10-31  1.069776  1.057067  1.062219  1.037789  1.062219   \n",
       "12340   92655  2023-11-30  1.042063  1.025157  1.032508  0.896984  1.032508   \n",
       "12341   92655  2023-12-29  0.971803  0.995099  0.952077  1.102215  0.952077   \n",
       "\n",
       "           RETX  \n",
       "0      0.172727  \n",
       "1      0.077519  \n",
       "2     -0.115108  \n",
       "3     -0.073171  \n",
       "4      0.000000  \n",
       "...         ...  \n",
       "12337 -0.058831  \n",
       "12338  0.057934  \n",
       "12339  0.062219  \n",
       "12340  0.032508  \n",
       "12341 -0.047923  \n",
       "\n",
       "[12342 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/us_stock_processed.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BIDLO     ASKHI       PRC         VOL    ALTPRC\n",
      "489   -1.885714 -0.071429 -0.115385    0.759519 -0.115385\n",
      "509    0.483871 -2.346154  0.405797   -0.779043  0.405797\n",
      "530    1.956522 -3.742857  1.927835    0.418814  1.927835\n",
      "551   -0.250000 -0.152778 -0.204225    0.635786 -0.204225\n",
      "5835  -1.600000 -0.420334 -0.405310   -0.967240 -0.405310\n",
      "11221 -3.303922  1.545278  1.142857  106.983051  1.142857\n",
      "      BIDLO     ASKHI       PRC       VOL    ALTPRC\n",
      "0  0.269598  0.694277  0.124264  0.015996  0.124264\n",
      "1  0.720052  0.264120  0.347645  0.001743  0.347645\n",
      "2  1.000000  0.000000  1.000000  0.012840  1.000000\n",
      "3  0.580545  0.678893  0.086186  0.014850  0.086186\n",
      "4  0.323912  0.628298  0.000000  0.000000  0.000000\n",
      "5  0.000000  1.000000  0.663554  1.000000  0.663554\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['PERMNO', 'date', 'RET'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_normalized)\n\u001b[1;32m     29\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 30\u001b[0m df_raw \u001b[38;5;241m=\u001b[39m \u001b[43mdf_normalized\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPERMNO\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     31\u001b[0m df_raw\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m grouped \u001b[38;5;241m=\u001b[39m df_raw\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPERMNO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PERMNO', 'date', 'RET'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/us_stock.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# df.tail()\n",
    "\n",
    "target = 'RET'\n",
    "cols = list(df.columns)\n",
    "cols.remove(target)\n",
    "cols.remove('date')\n",
    "cols.remove('PERMNO')\n",
    "cols.remove('SPREAD')\n",
    "cols.remove('RETX')\n",
    "cols.remove('ALTPRCDT')\n",
    "cols.remove('BID')\n",
    "cols.remove('ASK')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "# print(df)\n",
    "df = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "df = df.pct_change()\n",
    "df.dropna(inplace=True)\n",
    "print(df)\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df), columns=cols)\n",
    "print(df_normalized)\n",
    "df.dropna(inplace=True)\n",
    "df_raw = df_normalized[['PERMNO', 'date'] + cols + [target]]\n",
    "df_raw.dropna(inplace=True)\n",
    "grouped = df_raw.groupby('PERMNO')\n",
    "\n",
    "for permno, group in grouped:\n",
    "    print(group)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PERMNO       date     BIDLO     ASKHI       PRC           VOL    ALTPRC\n",
      "2       10107 1986-04-30  0.001849  0.005171  0.006281 -1.089529e-05  0.006281\n",
      "3       10107 1986-05-30  0.005050  0.000649  0.002404 -2.546188e-05  0.002404\n",
      "4       10107 1986-06-30 -0.001301 -0.000414 -0.003312  4.447396e-06 -0.003312\n",
      "5       10107 1986-07-31 -0.002825 -0.002557 -0.002380  5.551599e-05 -0.002380\n",
      "6       10107 1986-08-29  0.000337 -0.000640  0.000000 -2.644406e-05  0.000000\n",
      "...       ...        ...       ...       ...       ...           ...       ...\n",
      "12589   92655 2023-08-31  0.000144  0.000000 -0.000116 -4.620912e-07 -0.000116\n",
      "12590   92655 2023-09-29 -0.000001 -0.000002  0.000122  2.722833e-07  0.000122\n",
      "12591   92655 2023-10-31  0.000147  0.000112  0.000123  6.295008e-08  0.000123\n",
      "12592   92655 2023-11-30  0.000083  0.000047  0.000061 -1.653581e-07  0.000061\n",
      "12593   92655 2023-12-29 -0.000053 -0.000009 -0.000087  1.829156e-07 -0.000087\n",
      "\n",
      "[12374 rows x 7 columns]\n",
      "     PERMNO       date     BIDLO     ASKHI       PRC           VOL    ALTPRC\n",
      "2     10107 1986-04-30  0.001849  0.005171  0.006281 -1.089529e-05  0.006281\n",
      "3     10107 1986-05-30  0.005050  0.000649  0.002404 -2.546188e-05  0.002404\n",
      "4     10107 1986-06-30 -0.001301 -0.000414 -0.003312  4.447396e-06 -0.003312\n",
      "5     10107 1986-07-31 -0.002825 -0.002557 -0.002380  5.551599e-05 -0.002380\n",
      "6     10107 1986-08-29  0.000337 -0.000640  0.000000 -2.644406e-05  0.000000\n",
      "..      ...        ...       ...       ...       ...           ...       ...\n",
      "450   10107 2023-08-31 -0.000130 -0.000179 -0.000072 -4.209386e-08 -0.000072\n",
      "451   10107 2023-09-29 -0.000043  0.000021 -0.000112 -2.737976e-08 -0.000112\n",
      "452   10107 2023-10-31  0.000013  0.000017  0.000224  7.129985e-08  0.000224\n",
      "453   10107 2023-11-30  0.000333  0.000362  0.000357  6.963262e-09  0.000357\n",
      "454   10107 2023-12-29  0.000166 -0.000045 -0.000020 -1.328196e-08 -0.000020\n",
      "\n",
      "[453 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/us_stock.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 定义目标列和需要保留的列\n",
    "target = 'RET'\n",
    "cols = list(df.columns)\n",
    "cols.remove(target)\n",
    "cols.remove('date')\n",
    "cols.remove('PERMNO')\n",
    "cols.remove('SPREAD')\n",
    "cols.remove('RETX')\n",
    "cols.remove('ALTPRCDT')\n",
    "cols.remove('BID')\n",
    "cols.remove('ASK')\n",
    "\n",
    "# 计算需要百分比变化的列\n",
    "df_numeric = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "df_pct_change = df_numeric.pct_change() / df_numeric.shift(1)\n",
    "\n",
    "# 保留'PERMNO'和'date'列\n",
    "df_final = pd.concat([df[['PERMNO', 'date']], df_pct_change], axis=1)\n",
    "\n",
    "# 删除缺失值\n",
    "df_final.dropna(inplace=True)\n",
    "\n",
    "# 打印结果\n",
    "print(df_final)\n",
    "\n",
    "# # 保留原始数据中的'PERMNO', 'date'和需要的列\n",
    "# df_raw = pd.concat([df[['PERMNO', 'date']], df[cols], df[[target]]], axis=1)\n",
    "# df_raw.dropna(inplace=True)\n",
    "\n",
    "# 按'PERMNO'分组\n",
    "grouped = df_final.groupby('PERMNO')\n",
    "\n",
    "# 打印第一个分组的数据\n",
    "for permno, group in grouped:\n",
    "    print(group)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4174392/1921286449.py:3: DtypeWarning: Columns (7,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/home/liyuante/llm4ts/us_stock_all.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>BIDLO</th>\n",
       "      <th>ASKHI</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>BID</th>\n",
       "      <th>ASK</th>\n",
       "      <th>OPENPRC</th>\n",
       "      <th>NUMTRD</th>\n",
       "      <th>RETX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263616</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>UNH</td>\n",
       "      <td>518.02002</td>\n",
       "      <td>523.01001</td>\n",
       "      <td>520.31000</td>\n",
       "      <td>1759571.0</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>520.47998</td>\n",
       "      <td>520.48999</td>\n",
       "      <td>519.88000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263617</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>UNH</td>\n",
       "      <td>517.96997</td>\n",
       "      <td>521.47998</td>\n",
       "      <td>520.03003</td>\n",
       "      <td>1390912.0</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>520.10999</td>\n",
       "      <td>520.12000</td>\n",
       "      <td>519.88000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263618</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>UNH</td>\n",
       "      <td>519.35999</td>\n",
       "      <td>523.15997</td>\n",
       "      <td>522.78998</td>\n",
       "      <td>1851840.0</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>522.95001</td>\n",
       "      <td>523.09003</td>\n",
       "      <td>519.75000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263619</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>UNH</td>\n",
       "      <td>522.94000</td>\n",
       "      <td>527.87000</td>\n",
       "      <td>524.90002</td>\n",
       "      <td>2001208.0</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>525.07001</td>\n",
       "      <td>525.21002</td>\n",
       "      <td>523.46997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263620</th>\n",
       "      <td>92655</td>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>UNH</td>\n",
       "      <td>523.91998</td>\n",
       "      <td>528.23999</td>\n",
       "      <td>526.46997</td>\n",
       "      <td>2080197.0</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>526.53998</td>\n",
       "      <td>526.94000</td>\n",
       "      <td>525.97998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PERMNO        date TICKER      BIDLO      ASKHI        PRC        VOL  \\\n",
       "263616   92655  2023-12-22    UNH  518.02002  523.01001  520.31000  1759571.0   \n",
       "263617   92655  2023-12-26    UNH  517.96997  521.47998  520.03003  1390912.0   \n",
       "263618   92655  2023-12-27    UNH  519.35999  523.15997  522.78998  1851840.0   \n",
       "263619   92655  2023-12-28    UNH  522.94000  527.87000  524.90002  2001208.0   \n",
       "263620   92655  2023-12-29    UNH  523.91998  528.23999  526.46997  2080197.0   \n",
       "\n",
       "             RET        BID        ASK    OPENPRC  NUMTRD      RETX  \n",
       "263616  0.000827  520.47998  520.48999  519.88000     NaN  0.000827  \n",
       "263617 -0.000538  520.10999  520.12000  519.88000     NaN -0.000538  \n",
       "263618  0.005307  522.95001  523.09003  519.75000     NaN  0.005307  \n",
       "263619  0.004036  525.07001  525.21002  523.46997     NaN  0.004036  \n",
       "263620  0.002991  526.53998  526.94000  525.97998     NaN  0.002991  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/us_stock_all.csv')\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4174392/2852674171.py:4: DtypeWarning: Columns (7,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/home/liyuante/llm4ts/us_stock_all.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TICKER       date         BIDLO     ASKHI       PRC           VOL  \\\n",
      "1585     MSFT 1992-06-16 -4.444444e-04 -0.000247 -0.000523  3.165859e-08   \n",
      "1586     MSFT 1992-06-17 -1.902497e-04 -0.000555 -0.000071  1.223073e-07   \n",
      "1587     MSFT 1992-06-18 -9.780429e-05  0.000280 -0.000024 -1.015274e-07   \n",
      "1588     MSFT 1992-06-19  3.471533e-04 -0.000089  0.000239 -1.221880e-07   \n",
      "1589     MSFT 1992-06-22 -2.361805e-04  0.000045  0.000139  1.966328e-07   \n",
      "...       ...        ...           ...       ...       ...           ...   \n",
      "263616    UNH 2023-12-22  5.697367e-06  0.000008  0.000002 -1.179126e-07   \n",
      "263617    UNH 2023-12-26 -1.865138e-07 -0.000006 -0.000001 -1.190724e-07   \n",
      "263618    UNH 2023-12-27  5.180980e-06  0.000006  0.000010  2.382505e-07   \n",
      "263619    UNH 2023-12-28  1.327233e-05  0.000017  0.000008  4.355627e-08   \n",
      "263620    UNH 2023-12-29  3.583550e-06  0.000001  0.000006  1.972342e-08   \n",
      "\n",
      "             OPENPRC       RETX  \n",
      "1585    8.888889e-05  -0.039604  \n",
      "1586   -5.262927e-04  -0.005155  \n",
      "1587    9.512485e-05  -0.001727  \n",
      "1588    9.382623e-05   0.017301  \n",
      "1589   -4.627701e-05   0.010204  \n",
      "...              ...        ...  \n",
      "263616  3.714207e-06   0.000827  \n",
      "263617  0.000000e+00  -0.000538  \n",
      "263618 -4.809912e-07   0.005307  \n",
      "263619  1.377052e-05   0.004036  \n",
      "263620  9.159925e-06   0.002991  \n",
      "\n",
      "[164685 rows x 8 columns]\n",
      "      TICKER       date     BIDLO     ASKHI       PRC           VOL   OPENPRC  \\\n",
      "24397   AAPL 1980-12-12 -0.003141 -0.003119 -0.003819  0.000000e+00  0.000000   \n",
      "27307   AAPL 1992-06-16 -0.001361 -0.000686 -0.001219  5.848541e-07 -0.000772   \n",
      "27308   AAPL 1992-06-17 -0.000736 -0.001017 -0.000721 -5.413801e-08 -0.001027   \n",
      "27309   AAPL 1992-06-18 -0.001019 -0.000103 -0.000997  1.629263e-07 -0.000625   \n",
      "27310   AAPL 1992-06-19 -0.000499 -0.001249 -0.000244 -6.904507e-09 -0.000665   \n",
      "...      ...        ...       ...       ...       ...           ...       ...   \n",
      "35246   AAPL 2023-12-22 -0.000014 -0.000043 -0.000028 -4.418144e-09 -0.000024   \n",
      "35247   AAPL 2023-12-26 -0.000004 -0.000040 -0.000015 -6.058560e-09 -0.000041   \n",
      "35248   AAPL 2023-12-27 -0.000047 -0.000010  0.000003  2.332135e-08 -0.000030   \n",
      "35249   AAPL 2023-12-28  0.000057  0.000031  0.000012 -6.127177e-09  0.000045   \n",
      "35250   AAPL 2023-12-29 -0.000039 -0.000007 -0.000028  7.425538e-09 -0.000006   \n",
      "\n",
      "            RETX  \n",
      "24397          C  \n",
      "27307  -0.064133  \n",
      "27308  -0.035533  \n",
      "27309  -0.047368  \n",
      "27310  -0.011050  \n",
      "...          ...  \n",
      "35246  -0.005547  \n",
      "35247  -0.002841  \n",
      "35248   0.000518  \n",
      "35249   0.002226  \n",
      "35250  -0.005424  \n",
      "\n",
      "[7937 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/us_stock_all.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 定义目标列和需要保留的列\n",
    "target = 'RET'\n",
    "cols = list(df.columns)\n",
    "cols.remove(target)\n",
    "cols.remove('date')\n",
    "cols.remove('PERMNO')\n",
    "cols.remove('TICKER')\n",
    "cols.remove('NUMTRD')\n",
    "cols.remove('RETX')\n",
    "cols.remove('BID')\n",
    "cols.remove('ASK')\n",
    "\n",
    "# 计算需要百分比变化的列\n",
    "df_numeric = df[cols].apply(pd.to_numeric, errors='coerce')\n",
    "df_pct_change = df_numeric.pct_change() / df_numeric.shift(1)\n",
    "\n",
    "# 保留'PERMNO'和'date'列\n",
    "df_final = pd.concat([df[['TICKER', 'date']], df_pct_change, df[['RETX']]], axis=1)\n",
    "\n",
    "# 删除缺失值\n",
    "df_final.dropna(inplace=True)\n",
    "\n",
    "# 打印结果\n",
    "print(df_final)\n",
    "\n",
    "# 按'PERMNO'分组\n",
    "grouped = df_final.groupby('TICKER')\n",
    "\n",
    "# 打印第一个分组的数据\n",
    "for permno, group in grouped:\n",
    "    print(group)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TICKER        min        max time_span\n",
      "0    AAPL 2000-01-03 2023-12-29 8761 days\n",
      "1    AMGN 2000-01-03 2023-12-29 8761 days\n",
      "2    AMZN 2000-01-03 2023-12-29 8761 days\n",
      "3     AXP 2000-01-03 2023-12-29 8761 days\n",
      "4     BAC 2000-01-03 2023-12-29 8761 days\n",
      "5     BEL 2000-01-03 2000-06-30  179 days\n",
      "6     CAT 2000-01-03 2023-12-29 8761 days\n",
      "7     CMB 2000-01-03 2000-12-29  361 days\n",
      "8     CRM 2004-06-24 2023-12-29 7127 days\n",
      "9    CSCO 2000-01-03 2023-12-29 8761 days\n",
      "10   CYSP 2000-01-03 2000-04-05   93 days\n",
      "11    DIS 2000-01-03 2023-12-29 8761 days\n",
      "12    DOW 2000-01-03 2017-09-01 6451 days\n",
      "13   FOTO 2000-01-03 2001-08-22  597 days\n",
      "14   GSVI 2000-04-06 2001-03-14  342 days\n",
      "15    ICG 2023-03-17 2023-12-29  287 days\n",
      "16    JNJ 2000-01-03 2023-12-29 8761 days\n",
      "17    JPM 2001-01-02 2023-12-29 8396 days\n",
      "18    KOG 2006-06-21 2014-12-08 3092 days\n",
      "19    MCD 2000-01-03 2023-12-29 8761 days\n",
      "20    MMM 2000-01-03 2023-12-29 8761 days\n",
      "21   MSFT 2000-01-03 2023-12-29 8761 days\n",
      "22    NKE 2000-01-03 2023-12-29 8761 days\n",
      "23     PG 2000-01-03 2023-12-29 8761 days\n",
      "24    UNH 2000-01-03 2023-12-29 8761 days\n",
      "25      V 2008-03-20 2023-12-29 5762 days\n",
      "26     VZ 2000-07-03 2023-12-29 8579 days\n",
      "27    WMT 2000-01-03 2023-12-29 8761 days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df['date'] = pd.to_datetime(df_final['date'])\n",
    "df = df[df['date'] >= '2000-01-01']\n",
    "\n",
    "# 计算每个 Ticker 的时间跨度区间\n",
    "time_span = df.groupby('TICKER')['date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# 计算每个 Ticker 的时间跨度区间\n",
    "time_span['time_span'] = time_span['max'] - time_span['min']\n",
    "\n",
    "# 显示结果\n",
    "print(time_span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TICKER        min        max  time_span_days\n",
      "0    AAPL 2000-01-03 2023-12-29            8761\n",
      "1    AMGN 2000-01-03 2023-12-29            8761\n",
      "2    AMZN 2000-01-03 2023-12-29            8761\n",
      "3     AXP 2000-01-03 2023-12-29            8761\n",
      "4     BAC 2000-01-03 2023-12-29            8761\n",
      "6     CAT 2000-01-03 2023-12-29            8761\n",
      "9    CSCO 2000-01-03 2023-12-29            8761\n",
      "11    DIS 2000-01-03 2023-12-29            8761\n",
      "16    JNJ 2000-01-03 2023-12-29            8761\n",
      "19    MCD 2000-01-03 2023-12-29            8761\n",
      "20    MMM 2000-01-03 2023-12-29            8761\n",
      "21   MSFT 2000-01-03 2023-12-29            8761\n",
      "22    NKE 2000-01-03 2023-12-29            8761\n",
      "23     PG 2000-01-03 2023-12-29            8761\n",
      "24    UNH 2000-01-03 2023-12-29            8761\n",
      "27    WMT 2000-01-03 2023-12-29            8761\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设您的数据已经加载到 DataFrame 中\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 筛选出2000年之后的数据\n",
    "df_filtered = df[df['date'] >= '2000-01-01']\n",
    "\n",
    "# 计算每个 TICKER 的时间跨度区间\n",
    "time_span = df_filtered.groupby('TICKER')['date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# 计算每个 TICKER 的时间跨度天数\n",
    "time_span['time_span_days'] = (time_span['max'] - time_span['min']).dt.days\n",
    "\n",
    "# 筛选出时间跨度为8761天的记录\n",
    "time_span_filtered = time_span[time_span['time_span_days'] == 8761]\n",
    "\n",
    "# 显示结果\n",
    "print(time_span_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TICKER       date         BIDLO     ASKHI       PRC           VOL  \\\n",
      "3492     MSFT 2000-01-03 -3.144872e-04  0.000063 -0.000014  4.867886e-07   \n",
      "3493     MSFT 2000-01-04  1.992985e-05 -0.000107 -0.000290  8.186480e-10   \n",
      "3494     MSFT 2000-01-05 -2.281735e-04 -0.000055  0.000094  6.830411e-09   \n",
      "3495     MSFT 2000-01-06 -8.359184e-05 -0.000185 -0.000294 -4.403477e-09   \n",
      "3496     MSFT 2000-01-07 -9.046294e-05 -0.000125  0.000119  4.360924e-09   \n",
      "...       ...        ...           ...       ...       ...           ...   \n",
      "263616    UNH 2023-12-22  5.697367e-06  0.000008  0.000002 -1.179126e-07   \n",
      "263617    UNH 2023-12-26 -1.865138e-07 -0.000006 -0.000001 -1.190724e-07   \n",
      "263618    UNH 2023-12-27  5.180980e-06  0.000006  0.000010  2.382505e-07   \n",
      "263619    UNH 2023-12-28  1.327233e-05  0.000017  0.000008  4.355627e-08   \n",
      "263620    UNH 2023-12-29  3.583550e-06  0.000001  0.000006  1.972342e-08   \n",
      "\n",
      "             OPENPRC       RETX  \n",
      "3492   -9.053871e-06  -0.001606  \n",
      "3493   -2.767315e-04  -0.033780  \n",
      "3494   -1.890056e-04   0.010544  \n",
      "3495    8.604099e-05  -0.033498  \n",
      "3496   -2.830518e-04   0.013068  \n",
      "...              ...        ...  \n",
      "263616  3.714207e-06   0.000827  \n",
      "263617  0.000000e+00  -0.000538  \n",
      "263618 -4.809912e-07   0.005307  \n",
      "263619  1.377052e-05   0.004036  \n",
      "263620  9.159925e-06   0.002991  \n",
      "\n",
      "[96586 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设您的数据已经加载到 DataFrame 中\n",
    "df = df_final\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 筛选出2000年之后的数据\n",
    "df_filtered = df[df['date'] >= '2000-01-01']\n",
    "\n",
    "# 计算每个 TICKER 的时间跨度区间\n",
    "time_span = df_filtered.groupby('TICKER')['date'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "# 计算每个 TICKER 的时间跨度天数\n",
    "time_span['time_span_days'] = (time_span['max'] - time_span['min']).dt.days\n",
    "\n",
    "# 筛选出时间跨度为8761天的 TICKER\n",
    "tickers_with_8761_days = time_span[time_span['time_span_days'] == 8761]['TICKER']\n",
    "\n",
    "# 让原始 df 仅保留这些 TICKER 的记录\n",
    "df_final = df_filtered[df_filtered['TICKER'].isin(tickers_with_8761_days)]\n",
    "\n",
    "# 显示结果\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已保存到 'ticker_csv_files' 文件夹中。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 创建一个输出文件夹来存储 CSV 文件\n",
    "output_folder = 'ticker_csv_files'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 对每个 TICKER 进行分组并保存到单独的 CSV 文件\n",
    "for ticker, group in df_final.groupby('TICKER'):\n",
    "    # 创建文件名，以 TICKER 名字命名\n",
    "    filename = os.path.join(output_folder, f'{ticker}.csv')\n",
    "    # 保存分组数据到 CSV 文件\n",
    "    group.to_csv(filename, index=False)\n",
    "\n",
    "print(\"所有文件已保存到 'ticker_csv_files' 文件夹中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     TICKER        date     BIDLO     ASKHI       PRC           VOL   OPENPRC  \\\n",
      "0      AAPL  2000-01-03  0.000221  0.000909  0.000863  1.518989e-06  0.000386   \n",
      "1      AAPL  2000-01-04 -0.000048 -0.000148 -0.000753 -8.029787e-09  0.000307   \n",
      "2      AAPL  2000-01-05  0.000177 -0.000005  0.000143  1.118394e-07 -0.000384   \n",
      "3      AAPL  2000-01-06 -0.000754 -0.000291 -0.000832 -2.858331e-09  0.000221   \n",
      "4      AAPL  2000-01-07  0.000055 -0.000524  0.000499 -5.719446e-08 -0.000855   \n",
      "...     ...         ...       ...       ...       ...           ...       ...   \n",
      "6029   AAPL  2023-12-22 -0.000014 -0.000043 -0.000028 -4.418144e-09 -0.000024   \n",
      "6030   AAPL  2023-12-26 -0.000004 -0.000040 -0.000015 -6.058560e-09 -0.000041   \n",
      "6031   AAPL  2023-12-27 -0.000047 -0.000010  0.000003  2.332135e-08 -0.000030   \n",
      "6032   AAPL  2023-12-28  0.000057  0.000031  0.000012 -6.127177e-09  0.000045   \n",
      "6033   AAPL  2023-12-29 -0.000039 -0.000007 -0.000028  7.425538e-09 -0.000006   \n",
      "\n",
      "          RETX  \n",
      "0     0.088754  \n",
      "1    -0.084310  \n",
      "2     0.014634  \n",
      "3    -0.086538  \n",
      "4     0.047368  \n",
      "...        ...  \n",
      "6029 -0.005547  \n",
      "6030 -0.002841  \n",
      "6031  0.000518  \n",
      "6032  0.002226  \n",
      "6033 -0.005424  \n",
      "\n",
      "[6034 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/liyuante/llm4ts/ticker_csv_files/AAPL.csv')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the last day of 2016: 4273\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is named 'df' and the date column is named 'date'\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter the dataframe for the year 2016\n",
    "df_2016 = df[df['date'].dt.year == 2016]\n",
    "\n",
    "# Find the index of the last day of 2016\n",
    "last_day_index = df_2016[df_2016['date'] == df_2016['date'].max()].index[0]\n",
    "\n",
    "print(\"Index of the last day of 2016:\", last_day_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the last day of 2020: 5280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataframe is named 'df' and the date column is named 'date'\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Filter the dataframe for the year 2020\n",
    "df_2020 = df[df['date'].dt.year == 2020]\n",
    "\n",
    "# Find the index of the last day of 2020\n",
    "last_day_index = df_2020[df_2020['date'] == df_2020['date'].max()].index[0]\n",
    "\n",
    "print(\"Index of the last day of 2020:\", last_day_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days from 2021-01-01 to 2023-12-31: 1095\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start_date = '2021-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "date_range = pd.date_range(start=start_date, end=end_date)\n",
    "num_days = len(date_range)\n",
    "\n",
    "print(\"Number of days from 2021-01-01 to 2023-12-31:\", num_days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique days in data from 2000-01-01 to 2016-12-31: 4274\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "start_date2 = '2000-01-01'\n",
    "end_date2 = '2016-12-31'\n",
    "\n",
    "df_filtered = df[(df['date'] >= start_date2) & (df['date'] <= end_date2)]\n",
    "\n",
    "# 获取数据中独特的日期数\n",
    "unique_dates_in_data = df_filtered['date'].nunique()\n",
    "\n",
    "print(\"Number of unique days in data from 2000-01-01 to 2016-12-31:\", unique_dates_in_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4223\n",
      "1206\n"
     ]
    }
   ],
   "source": [
    "num_train = int(len(df) * 0.7)\n",
    "print(num_train)\n",
    "num_test = int(len(df) * 0.2)\n",
    "print(num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.10933667 -0.24987295 -0.08952767 -0.06186125 -0.9672878 ]\n",
      "  [-0.16738214  0.08650918 -0.13024166 -0.32311437  0.41691202]\n",
      "  [-0.07888711 -0.33419135 -0.08027037 -0.10675785 -1.3011038 ]\n",
      "  ...\n",
      "  [-0.01974932 -0.13382104 -0.12877095 -0.04473356 -0.46438015]\n",
      "  [-0.19979034 -0.03977328 -0.07261777 -0.26888725 -0.0924532 ]\n",
      "  [ 0.21964464  0.17360942 -0.12788124  0.12973325  0.73971653]]\n",
      "\n",
      " [[-0.16738214  0.08650918 -0.13024166 -0.32311437  0.41691202]\n",
      "  [-0.07888711 -0.33419135 -0.08027037 -0.10675785 -1.3011038 ]\n",
      "  [ 0.02111994  0.29418325 -0.12822914  0.01859067  1.2291118 ]\n",
      "  ...\n",
      "  [-0.19979034 -0.03977328 -0.07261777 -0.26888725 -0.0924532 ]\n",
      "  [ 0.21964464  0.17360942 -0.12788124  0.12973325  0.73971653]\n",
      "  [-0.00147149 -0.16596603 -0.11425286  0.16251981 -0.59580874]]\n",
      "\n",
      " [[-0.07888711 -0.33419135 -0.08027037 -0.10675785 -1.3011038 ]\n",
      "  [ 0.02111994  0.29418325 -0.12822914  0.01859067  1.2291118 ]\n",
      "  [ 0.05367218  0.05116602 -0.11902136  0.25609985  0.27757004]\n",
      "  ...\n",
      "  [ 0.21964464  0.17360942 -0.12788124  0.12973325  0.73971653]\n",
      "  [-0.00147149 -0.16596603 -0.11425286  0.16251981 -0.59580874]\n",
      "  [-0.0297937   0.09917188 -0.13237187 -0.15288718  0.45237273]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.11347293 -0.03430527 -0.12217532 -0.10289995 -0.08233757]\n",
      "  [ 0.02079262  0.03553733 -0.13548681 -0.00262594  0.3060133 ]\n",
      "  [-0.03365815 -0.10201304 -0.11694811  0.00658513 -0.4626631 ]\n",
      "  ...\n",
      "  [-0.08328358 -0.06153255 -0.14351843 -0.053602   -0.25165316]\n",
      "  [-0.0789453  -0.04503657 -0.15344869 -0.07336266 -0.1506461 ]\n",
      "  [-0.03892133 -0.02431964  0.02440273 -0.0604077  -0.02526448]]\n",
      "\n",
      " [[ 0.02079262  0.03553733 -0.13548681 -0.00262594  0.3060133 ]\n",
      "  [-0.03365815 -0.10201304 -0.11694811  0.00658513 -0.4626631 ]\n",
      "  [-0.06449639 -0.06087741 -0.10606527 -0.08876923 -0.22970484]\n",
      "  ...\n",
      "  [-0.0789453  -0.04503657 -0.15344869 -0.07336266 -0.1506461 ]\n",
      "  [-0.03892133 -0.02431964  0.02440273 -0.0604077  -0.02526448]\n",
      "  [ 0.01731688 -0.01376469 -0.15386407  0.0246457   0.03849016]]\n",
      "\n",
      " [[-0.03365815 -0.10201304 -0.11694811  0.00658513 -0.4626631 ]\n",
      "  [-0.06449639 -0.06087741 -0.10606527 -0.08876923 -0.22970484]\n",
      "  [-0.06895022 -0.12591003 -0.06430723 -0.02589105 -0.58789545]\n",
      "  ...\n",
      "  [-0.03892133 -0.02431964  0.02440273 -0.0604077  -0.02526448]\n",
      "  [ 0.01731688 -0.01376469 -0.15386407  0.0246457   0.03849016]\n",
      "  [-0.03414487 -0.06096528 -0.07182264 -0.03353418 -0.24706194]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path = '/home/liyuante/llm4ts/Time-Series-Library/results/long_term_forecast_usa_1_Transformer_MY_ftM_sl96_ll48_pl96_dm16_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0/true.npy'\n",
    "\n",
    "data = np.load(file_path)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.00778739]\n",
      "  [ 0.00222146]\n",
      "  [-0.00411569]\n",
      "  ...\n",
      "  [-0.00748175]\n",
      "  [-0.01391876]\n",
      "  [-0.00872239]]\n",
      "\n",
      " [[-0.03435422]\n",
      "  [-0.00043218]\n",
      "  [-0.00787693]\n",
      "  ...\n",
      "  [-0.01039387]\n",
      "  [-0.01660348]\n",
      "  [-0.01929486]]\n",
      "\n",
      " [[ 0.00880417]\n",
      "  [-0.00367717]\n",
      "  [-0.01195544]\n",
      "  ...\n",
      "  [-0.01331899]\n",
      "  [-0.01964212]\n",
      "  [-0.00225623]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.02791192]\n",
      "  [ 0.00908184]\n",
      "  [ 0.00504025]\n",
      "  ...\n",
      "  [-0.03542716]\n",
      "  [-0.01896821]\n",
      "  [-0.02391225]]\n",
      "\n",
      " [[-0.00118321]\n",
      "  [ 0.00275208]\n",
      "  [-0.00258481]\n",
      "  ...\n",
      "  [-0.01431011]\n",
      "  [-0.02496526]\n",
      "  [-0.02835831]]\n",
      "\n",
      " [[ 0.00956569]\n",
      "  [-0.00433493]\n",
      "  [-0.01119736]\n",
      "  ...\n",
      "  [-0.02091309]\n",
      "  [-0.03120854]\n",
      "  [-0.02647299]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path = '/home/liyuante/llm4ts/Time-Series-Library/results/long_term_forecast_usa_1_Transformer_MY_ftM_sl96_ll48_pl96_dm16_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0/pred.npy'\n",
    "\n",
    "data = np.load(file_path)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liyuante/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset_ETT_hour' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      3\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETTh1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mDataset_ETT_hour\u001b[49m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETTh2\u001b[39m\u001b[38;5;124m'\u001b[39m: Dataset_ETT_hour,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETTm1\u001b[39m\u001b[38;5;124m'\u001b[39m: Dataset_ETT_minute,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETTm2\u001b[39m\u001b[38;5;124m'\u001b[39m: Dataset_ETT_minute,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m'\u001b[39m: Dataset_Custom,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm4\u001b[39m\u001b[38;5;124m'\u001b[39m: Dataset_M4,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPSM\u001b[39m\u001b[38;5;124m'\u001b[39m: PSMSegLoader,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSL\u001b[39m\u001b[38;5;124m'\u001b[39m: MSLSegLoader,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMAP\u001b[39m\u001b[38;5;124m'\u001b[39m: SMAPSegLoader,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMD\u001b[39m\u001b[38;5;124m'\u001b[39m: SMDSegLoader,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSWAT\u001b[39m\u001b[38;5;124m'\u001b[39m: SWATSegLoader,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUEA\u001b[39m\u001b[38;5;124m'\u001b[39m: UEAloader,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMY\u001b[39m\u001b[38;5;124m'\u001b[39m: Dataset_Custom_Stock\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_provider\u001b[39m(args, flag):\n\u001b[1;32m     21\u001b[0m     Data \u001b[38;5;241m=\u001b[39m data_dict[args\u001b[38;5;241m.\u001b[39mdata]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset_ETT_hour' is not defined"
     ]
    }
   ],
   "source": [
    "from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_M4, PSMSegLoader, \\\n",
    "    MSLSegLoader, SMAPSegLoader, SMDSegLoader, SWATSegLoader, UEAloader, Dataset_Custom_Stock\n",
    "from data_provider.uea import collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dict = {\n",
    "    'ETTh1': Dataset_ETT_hour,\n",
    "    'ETTh2': Dataset_ETT_hour,\n",
    "    'ETTm1': Dataset_ETT_minute,\n",
    "    'ETTm2': Dataset_ETT_minute,\n",
    "    'custom': Dataset_Custom,\n",
    "    'm4': Dataset_M4,\n",
    "    'PSM': PSMSegLoader,\n",
    "    'MSL': MSLSegLoader,\n",
    "    'SMAP': SMAPSegLoader,\n",
    "    'SMD': SMDSegLoader,\n",
    "    'SWAT': SWATSegLoader,\n",
    "    'UEA': UEAloader,\n",
    "    'MY': Dataset_Custom_Stock\n",
    "}\n",
    "\n",
    "\n",
    "def data_provider(args, flag):\n",
    "    Data = data_dict[args.data]\n",
    "    timeenc = 0 if args.embed != 'timeF' else 1\n",
    "\n",
    "    shuffle_flag = False if flag == 'test' else True\n",
    "    drop_last = False\n",
    "    batch_size = args.batch_size\n",
    "    freq = args.freq\n",
    "\n",
    "    if args.task_name == 'anomaly_detection':\n",
    "        drop_last = False\n",
    "        data_set = Data(\n",
    "            args = args,\n",
    "            root_path=args.root_path,\n",
    "            win_size=args.seq_len,\n",
    "            flag=flag,\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n",
    "    elif args.task_name == 'classification':\n",
    "        drop_last = False\n",
    "        data_set = Data(\n",
    "            args = args,\n",
    "            root_path=args.root_path,\n",
    "            flag=flag,\n",
    "        )\n",
    "\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last,\n",
    "            collate_fn=lambda x: collate_fn(x, max_len=args.seq_len)\n",
    "        )\n",
    "        return data_set, data_loader\n",
    "    else:\n",
    "        if args.data == 'm4':\n",
    "            drop_last = False\n",
    "        data_set = Data(\n",
    "            args = args,\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            timeenc=timeenc,\n",
    "            freq=freq,\n",
    "            seasonal_patterns=args.seasonal_patterns\n",
    "        )\n",
    "        print(flag, len(data_set))\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "        return data_set, data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_provider'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/io/pickle.py:208\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_provider'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the pickle file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/liyuante/llm4ts/Time-Series-Library/test_data.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# View the contents of the DataFrame\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/io/pickle.py:213\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/compat/pickle_compat.py:275\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/pickle.py:1537\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/site-packages/pandas/compat/pickle_compat.py:206\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    204\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[1;32m    205\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm4ts38/lib/python3.8/pickle.py:1579\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1577\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[1;32m   1578\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[0;32m-> 1579\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data_provider'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "df = pd.read_pickle('/home/liyuante/llm4ts/Time-Series-Library/test_data.pkl')\n",
    "\n",
    "# View the contents of the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm4ts38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
